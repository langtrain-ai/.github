<div align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/langtrain-ai/langtrain/main/static/langtrain-use-dark.png">
    <img alt="Langtrain" src="https://raw.githubusercontent.com/langtrain-ai/langtrain/main/static/langtrain-white.png" width="600" />
  </picture>
</div>

<p align="center">
  <em>Elegant, efficient, and effortless LLM training for everyone</em>
</p>

<br>

## âœ¨ Philosophy

> *"The best tools are invisibleâ€”they amplify your capabilities without getting in the way."*

**Langtrain** embodies this philosophy. We've distilled the complexity of LLM training into two elegant modules, each crafted with precision to serve distinct yet complementary purposes. Whether you're shaping language or vision, Langtrain adapts to your workflow, not the other way around.

<br>

## ğŸ­ The Dual Nature of Intelligence

<table>
<tr>
<td width="50%" align="center">

### ğŸ“ **Langtune**
*The Art of Language*

Transform text models with surgical precision. Fine-tune conversations, adapt domains, and craft specialized language understandingâ€”all with the elegance of LoRA efficiency.

```python
from langtrain import langtune

# Poetry in code
model = langtune.create(
    base="microsoft/DialoGPT-medium",
    task="conversational",
    efficiency="maximum"
)

model.train("your_conversations.json")
```

</td>
<td width="50%" align="center">

### ğŸ‘ï¸ **Langvision**
*The Science of Sight*

Bridge the gap between pixels and meaning. Train vision-language models that understand both what they see and what it means in context.

```python
from langtrain import langvision

# Vision meets understanding
model = langvision.create(
    base="microsoft/kosmos-2-patch14-224",
    modality="vision-language",
    precision="high"
)

model.train("images/", "captions.json")
```

</td>
</tr>
</table>

<br>

## ğŸš€ Quickstart

<details>
<summary><strong>ğŸ”§ Installation</strong></summary>

```bash
# The complete experience
pip install langtrain

# Focused installations
pip install langtrain[text]     # Pure language
pip install langtrain[vision]   # Pure vision
```

</details>

<details>
<summary><strong>âš¡ First Steps</strong></summary>

```python
# Your first model in three lines
import langtrain as lt

trainer = lt.create_trainer("gpt2", "your_data.json")
trainer.train()
```

</details>

<details>
<summary><strong>ğŸ¯ Advanced Usage</strong></summary>

```python
# Fine-grained control
trainer = lt.LoRATrainer(
    model="llama-7b",
    dataset="domain_specific.json",
    config=lt.LoRAConfig(
        rank=16,
        alpha=32,
        dropout=0.1
    ),
    optimization=lt.OptimizationConfig(
        learning_rate=2e-4,
        warmup_steps=100,
        scheduler="cosine"
    )
)

# Train with monitoring
trainer.train(
    epochs=3,
    callbacks=[
        lt.callbacks.EarlyStoppingCallback(),
        lt.callbacks.ModelCheckpointCallback(),
        lt.callbacks.TensorBoardCallback()
    ]
)
```

</details>

<br>

## ğŸ¨ Design Principles

<div align="center">

| Principle | Implementation |
|-----------|----------------|
| **ğŸ¯ Simplicity** | Complex tasks simplified to single function calls |
| **âš¡ Efficiency** | LoRA fine-tuning reduces memory usage by 95% |
| **ğŸ”§ Modularity** | Mix and match components for your specific needs |
| **ğŸŒ Accessibility** | Open-source with comprehensive documentation |
| **ğŸ“ˆ Scalability** | From laptop experiments to production clusters |

</div>

<br>

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Langtrain                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ Langtune              â”‚  ğŸ‘ï¸ Langvision                  â”‚
â”‚  â”œâ”€ Text Models           â”‚  â”œâ”€ Vision Models               â”‚
â”‚  â”œâ”€ Conversational AI     â”‚  â”œâ”€ Image Captioning           â”‚
â”‚  â”œâ”€ Domain Adaptation     â”‚  â”œâ”€ Visual Q&A                 â”‚
â”‚  â””â”€ Language Tasks        â”‚  â””â”€ Multimodal Understanding   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Core Framework                          â”‚
â”‚  â”œâ”€ LoRA Implementation   â”œâ”€ Training Orchestration         â”‚
â”‚  â”œâ”€ Model Registry        â”œâ”€ Distributed Computing          â”‚
â”‚  â”œâ”€ Dataset Processing    â””â”€ Performance Monitoring         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<br>

## ğŸ“š Learn & Explore

<div align="center">

| Resource | Description |
|----------|-------------|
| [ğŸ“– **Documentation**](https://langtrain.ai/docs) | Comprehensive guides and API reference |
| [ğŸ¯ **Tutorials**](https://github.com/langtrain-ai/langtrain/tree/main/tutorials) | Step-by-step learning paths |
| [ğŸ’¡ **Examples**](https://github.com/langtrain-ai/langtrain/tree/main/examples) | Real-world use cases and implementations |
| [ğŸ¥ **Videos**](https://youtube.com/@langtrain) | Visual learning and demonstrations |
| [ğŸ“ **Blog**](https://blog.langtrain.ai) | Deep dives and technical insights |

</div>

<br>

## ğŸ¤ Community

<div align="center">

**Join thousands of developers building the future of AI**

[![GitHub](https://img.shields.io/badge/GitHub-langtrain--ai-black?style=for-the-badge&logo=github)](https://github.com/langtrain-ai/langtrain)
[![Discord](https://img.shields.io/badge/Discord-Join%20Community-7289DA?style=for-the-badge&logo=discord)](https://discord.gg/langtrain)
[![Twitter](https://img.shields.io/badge/Twitter-@10Priteshraj-1DA1F2?style=for-the-badge&logo=twitter)](https://twitter.com/10Priteshraj)

</div>

### ğŸŒŸ Contributors

<div align="center">
<a href="https://github.com/langtrain-ai/langtrain/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=langtrain-ai/langtrain" />
</a>
</div>

### ğŸ¯ How to Contribute

<details>
<summary><strong>Ways to make an impact</strong></summary>

- **ğŸ› Bug Reports**: Help us identify and fix issues
- **ğŸ’¡ Feature Requests**: Share your ideas for improvements
- **ğŸ“– Documentation**: Improve guides and examples
- **ğŸ”§ Code Contributions**: Implement new features or optimizations
- **ğŸ¨ Design**: Enhance user experience and visual elements
- **ğŸŒ Community**: Help others in discussions and forums

</details>

<br>

## ğŸ“„ License

<div align="center">

**Apache License 2.0**

*Open-source software that respects both users and contributors*

</div>

<br>

## ğŸ™ Acknowledgments

<div align="center">

*Built with gratitude for the open-source community*

**Special thanks to:**
- The PyTorch team for the robust foundation
- Hugging Face for democratizing AI
- The LoRA researchers for efficient fine-tuning
- Our contributors for making this possible

</div>

---

<br>

<div align="center">
  <img src="https://img.shields.io/badge/Made%20in-India%20ğŸ‡®ğŸ‡³-orange?style=for-the-badge" alt="Made in India">
  <br><br>
  <em>Crafted with â¤ï¸ by the Langtrain community</em>
  <br><br>
  <strong>â­ Star us on GitHub â€¢ ğŸ”„ Share with friends â€¢ ğŸ’¬ Join our community</strong>
</div>
